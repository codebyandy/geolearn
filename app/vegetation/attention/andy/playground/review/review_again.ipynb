{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21071451-b681-4d88-a287-750b0840453e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e649ce29-9b21-416a-8295-182fee6f69f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading package hydroDL\n"
     ]
    }
   ],
   "source": [
    "import hydroDL.data.dbVeg\n",
    "from hydroDL.data import dbVeg\n",
    "import importlib\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from hydroDL import utils\n",
    "from hydroDL.post import mapplot, axplot, figplot\n",
    "import matplotlib.pyplot as plt\n",
    "from hydroDL.model import rnn, crit, trainBasin\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from hydroDL.data import DataModel\n",
    "from hydroDL.master import basinFull, slurm, dataTs2Range\n",
    "import torch.optim as optim\n",
    "from hydroDL import kPath\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import dill\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0cab2a-19d5-44c6-abb6-b09683404533",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 45 # init rho\n",
    "dataName = 'singleDaily' # init dataName\n",
    "importlib.reload(hydroDL.data.dbVeg) # reimport library\n",
    "df = dbVeg.DataFrameVeg(dataName) # create DataFrameVeg class \n",
    "dm = DataModel(X=df.x, XC=df.xc, Y=df.y) # (?) create DataModel class (contains many confusing functions) \n",
    "siteIdLst = df.siteIdLst # get site list\n",
    "dm.trans(mtdDefault='minmax') # (?) some sort of data normalization\n",
    "dataTup = dm.getData() # get x, xc, y, and yc\n",
    "dataEnd, (iInd, jInd) = dataTs2Range(dataTup, rho, returnInd=True) # get data into form (# LFMC, 91 day window, varX) \n",
    "x, xc, y, yc = dataEnd # data from dataTs2Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb4cda6-a2a6-46af-9d15-bb09aaee5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of variables of interest\n",
    "varS = ['VV', 'VH', 'vh_vv']\n",
    "varL = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'ndvi', 'ndwi', 'nirv']\n",
    "varM = ['Fpar', 'Lai']\n",
    "iS = [df.varX.index(var) for var in varS]\n",
    "iL = [df.varX.index(var) for var in varL]\n",
    "iM = [df.varX.index(var) for var in varM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32554ab4-3ea4-4171-8c7c-cef5a7923014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each satellite, for each LFMC data point\n",
    "# create a list of days in the 91 day window that have data\n",
    "\n",
    "# nMat -- (# LFMC, # satellites)\n",
    "# nMat contains # of days each satellite has data for\n",
    "pSLst, pLLst, pMLst = list(), list(), list()\n",
    "ns = yc.shape[0]\n",
    "nMat = np.zeros([yc.shape[0], 3])\n",
    "for k in range(nMat.shape[0]):\n",
    "    tempS = x[:, k, iS] # x (rho, LFMC, varX) \n",
    "    pS = np.where(~np.isnan(tempS).any(axis=1))[0]\n",
    "    tempL = x[:, k, iL] # x (rho, LFMC, varX) \n",
    "    pL = np.where(~np.isnan(tempL).any(axis=1))[0]\n",
    "    tempM = x[:, k, iM] # x (rho, LFMC, varX) \n",
    "    pM = np.where(~np.isnan(tempM).any(axis=1))[0]\n",
    "    pSLst.append(pS)\n",
    "    pLLst.append(pL)\n",
    "    pMLst.append(pM)\n",
    "    nMat[k, :] = [len(pS), len(pL), len(pM)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd94ea7-b28d-4b5f-85a9-66117a120b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep if data if there is at least 1 day of data for \n",
    "# each satellite\n",
    "indKeep = np.where((nMat > 0).all(axis=1))[0]\n",
    "x = x[:, indKeep, :]\n",
    "xc = xc[indKeep, :]\n",
    "yc = yc[indKeep, :]\n",
    "nMat = nMat[indKeep, :]\n",
    "pSLst = [pSLst[k] for k in indKeep]\n",
    "pLLst = [pLLst[k] for k in indKeep]\n",
    "pMLst = [pMLst[k] for k in indKeep]\n",
    "jInd = jInd[indKeep]\n",
    "\n",
    "# update from just list of sites to sites per datapoint\n",
    "siteIdLst = [siteIdLst[k] for k in jInd] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67147e0-70ca-4c18-9ca7-d2c09595b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jSite, count = np.unique(jInd, return_counts=True) # sites, # of times site appears\n",
    "countAry = np.array([[x, y] for y, x in sorted(zip(count, jSite))]) # rearrange\n",
    "nRm = sum(countAry[:, 1] < 5) # # of sites that show up less than 5 times\n",
    "indSiteAll = countAry[nRm:, 0].astype(int) # remove sites that show up less than 5 times\n",
    "dictSubset = dict()\n",
    "\n",
    "# create 5 folds, each with train and test data\n",
    "for k in range(5):\n",
    "    siteTest = indSiteAll[k::5] \n",
    "    siteTrain = np.setdiff1d(indSiteAll, siteTest)\n",
    "    indTest = np.where(np.isin(jInd, siteTest))[0]\n",
    "    indTrain = np.where(np.isin(jInd, siteTrain))[0]\n",
    "    dictSubset['testSite_k{}5'.format(k)] = siteTest.tolist()\n",
    "    dictSubset['trainSite_k{}5'.format(k)] = siteTrain.tolist()\n",
    "    dictSubset['testInd_k{}5'.format(k)] = indTest.tolist()\n",
    "    dictSubset['trainInd_k{}5'.format(k)] = indTrain.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50478d90-fe9e-451a-a1b0-c845e607609c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40,  45, 215, 300, 305, 322,  11, 120, 164, 181, 189, 199, 204,\n",
       "       244, 291, 293,  39,  44,  46, 118, 123, 147, 162, 167, 177, 179,\n",
       "       198, 207, 287, 294, 297, 298, 315,  48, 192, 292, 295, 299,  33,\n",
       "        49,  50, 176, 191, 200, 208, 290, 313, 193, 296, 308, 320, 106,\n",
       "       144, 180, 182, 174, 175, 319,  47, 157, 159, 161, 201, 158, 188,\n",
       "        30, 316,  38, 140, 165, 186, 225, 286, 307, 318,  36,  41,  42,\n",
       "        43, 209, 210, 211, 213, 282, 314, 317,  92, 122, 125, 127,  21,\n",
       "        93, 270, 252, 255, 271, 133, 325, 254, 257,  16,  26,  96, 119,\n",
       "       124, 146, 149,  95,  97, 121, 148,  10,  32,  90,  98, 129, 185,\n",
       "       217,  20,  81, 166, 272,  86,  91, 131, 274,   9,  19,  35,  87,\n",
       "       155,  34,  37,  85, 156, 276, 277,  22,  82, 259, 273, 275, 281,\n",
       "        58, 260,  13,  23,  84,  88, 151, 216, 236, 237, 261,   5, 170,\n",
       "       249, 250, 263,  60,   6,  70, 171, 251, 288, 301,  27,  28,  62,\n",
       "       126, 168, 226,  72, 239,  56,  69,  71, 221, 224, 267, 268, 128,\n",
       "       266, 269, 285, 327,  12,  65, 105, 111, 324, 326,   2,  17,  25,\n",
       "        59,  61,  64, 134, 136, 187, 323,   1,   3,   4,  55, 219, 262,\n",
       "        57,  63,  66, 112, 114, 258,   7, 110, 220, 241, 304,   0,  73,\n",
       "        76, 212, 302, 321, 117, 243, 246,   8,  24,  31, 107, 173,  77,\n",
       "        78, 115, 303, 328,  54,  75,  79, 108, 113, 283,  80, 284,  74,\n",
       "       169, 245,  18,  51, 130, 132,  52,  53, 172, 280,  29, 279, 233,\n",
       "       278, 214, 218, 238, 222, 230, 235, 242,  15, 228, 142, 227, 183,\n",
       "       223, 184, 194, 195, 196, 197, 231, 234, 232, 137, 138, 265, 264,\n",
       "       102,  99, 103, 104, 139, 141])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a23f45c2-fe01-4ccf-9c0b-8f2f6c8548c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tInd = iInd\n",
    "siteInd = jInd\n",
    "trainInd = dictSubset['trainInd_k05']\n",
    "testInd = dictSubset['testInd_k05']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de57e5-7950-4983-ab7f-9eba195c7a9d",
   "metadata": {},
   "source": [
    "# Random subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "746c445f-644e-417e-bdc4-7ab6a1acaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSubset(opt='train', batch=1000):\n",
    "    # random sample within window\n",
    "    varS = ['VV', 'VH', 'vh_vv']\n",
    "    varL = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'ndvi', 'ndwi', 'nirv']\n",
    "    varM = ['Fpar', 'Lai'] \n",
    "    iS = [df.varX.index(var) for var in varS]\n",
    "    iL = [df.varX.index(var) for var in varL]\n",
    "    iM = [df.varX.index(var) for var in varM]\n",
    "    \n",
    "    if opt == 'train':\n",
    "        indSel = np.random.permutation(trainInd)[0:batch]\n",
    "    else:\n",
    "        indSel = testInd\n",
    "    ns = len(indSel)\n",
    "\n",
    "    # Step 1: Create a ns by bX matrix of vals 0 to nMat[indSel, X]\n",
    "    # random.randint(low, high=None, size=None)\n",
    "    rS = np.random.randint(0, nMat[indSel, 0], [bS, ns]).T\n",
    "    rL = np.random.randint(0, nMat[indSel, 1], [bL, ns]).T\n",
    "    rM = np.random.randint(0, nMat[indSel, 2], [bM, ns]).T\n",
    "    \n",
    "    pS = np.stack([pSLst[indSel[k]][rS[k, :]] for k in range(ns)], axis=0)\n",
    "    pL = np.stack([pLLst[indSel[k]][rL[k, :]] for k in range(ns)], axis=0)\n",
    "    pM = np.stack([pMLst[indSel[k]][rM[k, :]] for k in range(ns)], axis=0)\n",
    "    \n",
    "    matS1 = x[:, indSel, :][:, :, iS]\n",
    "    matL1 = x[:, indSel, :][:, :, iL]\n",
    "    matM1 = x[:, indSel, :][:, :, iM]\n",
    "    \n",
    "    xS = np.stack([matS1[pS[k, :], k, :] for k in range(ns)], axis=0)\n",
    "    xL = np.stack([matL1[pL[k, :], k, :] for k in range(ns)], axis=0)\n",
    "    xM = np.stack([matM1[pM[k, :], k, :] for k in range(ns)], axis=0)\n",
    "    \n",
    "    pS = (pS - rho) / rho\n",
    "    pL = (pL - rho) / rho\n",
    "    pM = (pM - rho) / rho\n",
    "    \n",
    "    return (\n",
    "        torch.tensor(xS, dtype=torch.float32),\n",
    "        torch.tensor(xL, dtype=torch.float32),\n",
    "        torch.tensor(xM, dtype=torch.float32),\n",
    "        torch.tensor(pS, dtype=torch.float32),\n",
    "        torch.tensor(pL, dtype=torch.float32),\n",
    "        torch.tensor(pM, dtype=torch.float32),\n",
    "        torch.tensor(xc[indSel, :], dtype=torch.float32),\n",
    "        torch.tensor(yc[indSel, 0], dtype=torch.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc4b17-ce2b-4ed8-a326-cc4f38ae766b",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "effb3d83-e0e1-4009-814e-08cac9b58c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = \"train\"\n",
    "batch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8c9c175-387f-4f99-a8a8-b6ee78af5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt == 'train':\n",
    "    indSel = np.random.permutation(trainInd)[0:batch]\n",
    "else:\n",
    "    indSel = testInd\n",
    "ns = len(indSel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "979c736d-43ed-41f7-8938-d32a471c20c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b2570bab-9ea2-469f-80fd-aa13da3a0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each lfmc in batch, get 8 random vals (w/ rep) from [0, # days for lfmc]\n",
    "rS = np.random.randint(0, nMat[indSel, 0], [bS, ns]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77cb00b9-855c-43da-aec3-15ced5ea3f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nMat[indSel, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "75d76171-e228-4edc-a809-82217d88cf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "064c4eb8-4419-4798-8817-52ab7a1c9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each lfmc in batch, choose 8 days based on vals in rS\n",
    "pS = np.stack([pSLst[indSel[k]][rS[k, :]] for k in range(ns)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f80e5870-9859-4cb1-82c9-a6017d5493a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3da2d211-9bdd-4df3-88b2-17b929f54442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pSLst[ index an lfmc point in the dataset ][ index bS random days ] \n",
    "# pSLst -- for each LFMC data point, a list of days in the 91 day window that have data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "33e52f84-c83d-441a-a01a-ed4bbfde9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "matS1 = x[:, indSel, :][:, :, iS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c2425cde-66ed-412a-a2d3-481b3887faeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 9970, 20)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # (rho, #lfmc, #var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bffce65d-45f4-409f-bb7c-681d6c06db6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 1000, 20)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select examples in batch\n",
    "x[:, indSel, :].shape  # (rho, batch size, #var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5317feb5-f4ed-4905-9ae6-d3a69b7ad120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 1000, 3)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select variables of interest\n",
    "x[:, indSel, :][:, :, iS].shape # (rho, batch size, #var desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e40a2a23-d24a-48a4-9fbd-6dc245fa0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "xS = np.stack([matS1[pS[k, :], k, :] for k in range(ns)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5da73d49-bc89-4789-9d5f-8ecb0273db6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example k, get the 8 days sampled\n",
    "pS[k, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2d5987a0-6dd4-4b22-bc91-30fa572204d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example k, index matS1 for [8 days, example k, all vars of interst]\n",
    "matS1[pS[k, :], k, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8cd1130b-5635-448a-9263-06502d3d6191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xS.shape # (# examples, 8 days, 3 variables of intest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2f4142d4-dd9a-4fc8-8199-a927b411c93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pS = (pS - rho) / rho\n",
    "pS.shape\n",
    "# normalize chose days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1fa1c637-48e0-416b-8a2d-8ce79ccd8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xS -- (1000, bS, 3)\n",
    "# xL -- (1000, bL, 8)\n",
    "# xM -- (1000, bM, 2)\n",
    "\n",
    "# pS -- (1000, bS)\n",
    "# pL -- (1000, bL)\n",
    "# pM -- (1000, bM)\n",
    "\n",
    "# xc -- (1000, 15)\n",
    "# yc -- (1000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad42b6-ff86-487a-b1dd-2128506fa71e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b335598-4d8a-405e-bb37-f40a09496b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeature(nn.Module):\n",
    "    def __init__(self, nTup, nxc, nh):\n",
    "        # nTup -- # of inputs for each satellite\n",
    "        # nxc -- # of const vars\n",
    "        # nh -- # hidden layers\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.lnXc = nn.Sequential(nn.Linear(nxc, nh), nn.ReLU(), nn.Linear(nh, nh))\n",
    "        self.lnLst = nn.ModuleList()\n",
    "        for n in nTup:\n",
    "            self.lnLst.append(\n",
    "                nn.Sequential(nn.Linear(n, nh), nn.ReLU(), nn.Linear(nh, nh))\n",
    "            )\n",
    "\n",
    "    def getPos(self, pos):\n",
    "        nh = self.nh\n",
    "        P = torch.zeros([pos.shape[0], pos.shape[1], nh], dtype=torch.float32)\n",
    "        for i in range(int(nh / 2)):\n",
    "            P[:, :, 2 * i] = torch.sin(pos / (i + 1) * torch.pi)\n",
    "            P[:, :, 2 * i + 1] = torch.cos(pos / (i + 1) * torch.pi)\n",
    "        return P\n",
    "\n",
    "    def forward(self, xTup, pTup, xc):\n",
    "        outLst = list()\n",
    "        for k in range(len(xTup)):\n",
    "            x = self.lnLst[k](xTup[k]) + self.getPos(pTup[k])\n",
    "            outLst.append(x)\n",
    "        outC = self.lnXc(xc)\n",
    "        # outLst[0].shape -> torch.Size([1000, 8, 32])\n",
    "        # outLst[1].shape -> torch.Size([1000, 6, 32])\n",
    "        # outLst[2].shape -> torch.Size([1000, 10, 32])\n",
    "        # outC[:, None, :].shape -> torch.Size([1000, 1, 32])\n",
    "        # out.shape -> torch.Size([1000, 25, 32])\n",
    "        out = torch.cat(outLst + [outC[:, None, :]], dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, nx, nh):\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.W_k = nn.Linear(nx, nh, bias=False)\n",
    "        self.W_q = nn.Linear(nx, nh, bias=False)\n",
    "        self.W_v = nn.Linear(nx, nh, bias=False)\n",
    "        self.W_o = nn.Linear(nh, nh, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = self.W_q(x), self.W_k(x), self.W_v(x)\n",
    "        d = q.shape[1]\n",
    "        score = torch.bmm(q.transpose(1, 2), k) / math.sqrt(d)\n",
    "        attention = torch.softmax(score, dim=-1)\n",
    "        out = torch.bmm(attention, v.transpose(1, 2))\n",
    "        out = self.W_o(out.transpose(1, 2))\n",
    "        return out\n",
    "\n",
    "\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, nh, ny):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(nh, nh)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(nh, ny)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n",
    "\n",
    "\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, norm_shape, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(norm_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "\n",
    "\n",
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, nTup, nxc, nh):\n",
    "        # nTup -- # of inputs for each satellite\n",
    "        # nxc -- # of const vars\n",
    "        # nh -- # hidden layers\n",
    "        super().__init__()\n",
    "        self.nTup = nTup\n",
    "        self.nxc = nxc\n",
    "        self.encoder = InputFeature(nTup, nxc, nh)\n",
    "        self.atten = AttentionLayer(nh, nh)\n",
    "        self.addnorm1 = AddNorm(nh, 0.1)\n",
    "        self.addnorm2 = AddNorm(nh, 0.1)\n",
    "        self.ffn1 = PositionWiseFFN(nh, nh)\n",
    "        self.ffn2 = PositionWiseFFN(nh, 1)\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, x, pos, xcT, lTup):\n",
    "        xIn = self.encoder(x, pos, xcT)\n",
    "        out = self.atten(xIn)\n",
    "        out = self.addnorm1(xIn, out)\n",
    "        out = self.ffn1(out)\n",
    "        out = self.addnorm2(xIn, out)\n",
    "        out = self.ffn2(out)\n",
    "        out = out.squeeze(-1)\n",
    "        k = 0\n",
    "        temp = 0\n",
    "        for i in lTup:\n",
    "            temp = temp + out[:, k : i + k].mean(-1)\n",
    "            k = k + i\n",
    "        temp = temp + out[:, k:].mean(-1)\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5b4f3-78d4-4ae6-b219-7b5fbdfabe04",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d6f3d7d-73f5-4619-aa37-4f9f826ce28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bS = 8\n",
    "bL = 6\n",
    "bM = 10\n",
    "nh = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8bdc2999-a92e-44d1-8510-1c4d33d71838",
   "metadata": {},
   "outputs": [],
   "source": [
    "xS, xL, xM, pS, pL, pM, xcT, yT = randomSubset()\n",
    "nTup = (xS.shape[-1], xL.shape[-1], xM.shape[-1])\n",
    "lTup = (xS.shape[1], xL.shape[1], xM.shape[1])\n",
    "nxc = xc.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "346d2aa9-7a23-4a46-902b-7c4d8ec8d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinalModel(nTup, nxc, nh)\n",
    "yP = model((xS, xL, xM), (pS, pL, pM), xcT, lTup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3dcd75ed-424a-4b8f-b749-d6e857ef6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss(reduction='mean')\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.LinearLR(\n",
    "    optimizer, start_factor=1.0, end_factor=0.01, total_iters=800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab50d5-a9db-4937-94c3-3d8e2418fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "nEp = 500\n",
    "nIterEp = 20\n",
    "for ep in range(nEp):\n",
    "    lossEp = 0\n",
    "    for i in range(nIterEp):\n",
    "        t0 = time.time()\n",
    "        xS, xL, xM, pS, pL, pM, xcT, yT = randomSubset()\n",
    "        t1 = time.time()\n",
    "        model.zero_grad()\n",
    "        yP = model((xS, xL, xM), (pS, pL, pM), xcT, lTup)\n",
    "        loss = loss_fn(yP, yT)\n",
    "        loss.backward()\n",
    "        t2 = time.time()\n",
    "        lossEp = lossEp + loss.item()\n",
    "        optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    xS, xL, xM, pS, pL, pM, xcT, yT = randomSubset('test')\n",
    "    yP = model((xS, xL, xM), (pS, pL, pM), xcT, lTup)\n",
    "    loss = loss_fn(yP, yT)\n",
    "    corr = np.corrcoef(yP.detach().numpy(), yT.detach().numpy())[0, 1]\n",
    "    if ep > 200:\n",
    "        scheduler.step()\n",
    "    print(\n",
    "        '{} {:.3f} {:.3f} {:.3f} time {:.2f} {:.2f}'.format(\n",
    "            ep, lossEp / nIterEp, loss.item(), corr, t1 - t0, t2 - t1\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
