{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21071451-b681-4d88-a287-750b0840453e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e649ce29-9b21-416a-8295-182fee6f69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydroDL.data.dbVeg\n",
    "from hydroDL.data import dbVeg\n",
    "import importlib\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from hydroDL import utils\n",
    "from hydroDL.post import mapplot, axplot, figplot\n",
    "import matplotlib.pyplot as plt\n",
    "from hydroDL.model import rnn, crit, trainBasin\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from hydroDL.data import DataModel\n",
    "from hydroDL.master import basinFull, slurm, dataTs2Range\n",
    "import torch.optim as optim\n",
    "from hydroDL import kPath\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import dill\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e0cab2a-19d5-44c6-abb6-b09683404533",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 45 # init rho\n",
    "dataName = 'singleDaily' # init dataName\n",
    "# dataName = 'singeDaily_og'\n",
    "importlib.reload(hydroDL.data.dbVeg) # reimport library\n",
    "df = dbVeg.DataFrameVeg(dataName) # create DataFrameVeg class \n",
    "dm = DataModel(X=df.x, XC=df.xc, Y=df.y) # (?) create DataModel class (contains many confusing functions) \n",
    "siteIdLst = df.siteIdLst # get site list\n",
    "dm.trans(mtdDefault='minmax') # (?) some sort of data normalization\n",
    "dataTup = dm.getData() # get x, xc, y, and yc\n",
    "dataEnd, (iInd, jInd) = dataTs2Range(dataTup, rho, returnInd=True) # get data into form (# LFMC, 91 day window, varX) \n",
    "x, xc, y, yc = dataEnd # data from dataTs2Range\n",
    "\n",
    "iInd = np.array(iInd)\n",
    "jInd = np.array(jInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c89557bb-0eee-4af9-bcd8-1def78ddb059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.varXC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bb4cda6-a2a6-46af-9d15-bb09aaee5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of variables of interest\n",
    "varS = ['VV', 'VH', 'vh_vv']\n",
    "varL = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'ndvi', 'ndwi', 'nirv']\n",
    "varM = [\"myd_b{}\".format(x) for x in range(1, 8)]\n",
    "iS = [df.varX.index(var) for var in varS]\n",
    "iL = [df.varX.index(var) for var in varL]\n",
    "iM = [df.varX.index(var) for var in varM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32554ab4-3ea4-4171-8c7c-cef5a7923014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each satellite, for each LFMC data point\n",
    "# create a list of days in the 91 day window that have data\n",
    "\n",
    "# nMat -- (# LFMC, # satellites)\n",
    "# nMat contains # of days each satellite has data for\n",
    "pSLst, pLLst, pMLst = list(), list(), list()\n",
    "ns = yc.shape[0]\n",
    "nMat = np.zeros([yc.shape[0], 3])\n",
    "for k in range(nMat.shape[0]):\n",
    "    tempS = x[:, k, iS] # x (rho, LFMC, varX) \n",
    "    pS = np.where(~np.isnan(tempS).any(axis=1))[0]\n",
    "    tempL = x[:, k, iL] # x (rho, LFMC, varX) \n",
    "    pL = np.where(~np.isnan(tempL).any(axis=1))[0]\n",
    "    tempM = x[:, k, iM] # x (rho, LFMC, varX) \n",
    "    pM = np.where(~np.isnan(tempM).any(axis=1))[0]\n",
    "    pSLst.append(pS)\n",
    "    pLLst.append(pL)\n",
    "    pMLst.append(pM)\n",
    "    nMat[k, :] = [len(pS), len(pL), len(pM)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8dd94ea7-b28d-4b5f-85a9-66117a120b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep if data if there is at least 1 day of data for \n",
    "# each satellite\n",
    "indKeep = np.where((nMat > 0).all(axis=1))[0]\n",
    "x = x[:, indKeep, :]\n",
    "xc = xc[indKeep, :]\n",
    "yc = yc[indKeep, :]\n",
    "nMat = nMat[indKeep, :]\n",
    "pSLst = [pSLst[k] for k in indKeep]\n",
    "pLLst = [pLLst[k] for k in indKeep]\n",
    "pMLst = [pMLst[k] for k in indKeep]\n",
    "jInd = jInd[indKeep]\n",
    "\n",
    "# update from just list of sites to sites per datapoint\n",
    "siteIdLst = [siteIdLst[k] for k in jInd] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f67147e0-70ca-4c18-9ca7-d2c09595b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jSite, count = np.unique(jInd, return_counts=True) # sites, # of times site appears\n",
    "countAry = np.array([[x, y] for y, x in sorted(zip(count, jSite))]) # rearrange\n",
    "nRm = sum(countAry[:, 1] < 5) # # of sites that show up less than 5 times\n",
    "indSiteAll = countAry[nRm:, 0].astype(int) # remove sites that show up less than 5 times\n",
    "dictSubset = dict()\n",
    "\n",
    "# create 5 folds, each with train and test data\n",
    "for k in range(5):\n",
    "    siteTest = indSiteAll[k::5] \n",
    "    siteTrain = np.setdiff1d(indSiteAll, siteTest)\n",
    "    indTest = np.where(np.isin(jInd, siteTest))[0]\n",
    "    indTrain = np.where(np.isin(jInd, siteTrain))[0]\n",
    "    dictSubset['testSite_k{}5'.format(k)] = siteTest.tolist()\n",
    "    dictSubset['trainSite_k{}5'.format(k)] = siteTrain.tolist()\n",
    "    dictSubset['testInd_k{}5'.format(k)] = indTest.tolist()\n",
    "    dictSubset['trainInd_k{}5'.format(k)] = indTrain.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a23f45c2-fe01-4ccf-9c0b-8f2f6c8548c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tInd = iInd\n",
    "siteInd = jInd\n",
    "trainInd = dictSubset['trainInd_k05']\n",
    "testInd = dictSubset['testInd_k05']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de57e5-7950-4983-ab7f-9eba195c7a9d",
   "metadata": {},
   "source": [
    "# Random subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "746c445f-644e-417e-bdc4-7ab6a1acaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSubset(opt='train', batch=1000):\n",
    "    # random sample within window\n",
    "    varS = ['VV', 'VH', 'vh_vv']\n",
    "    varL = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'ndvi', 'ndwi', 'nirv']\n",
    "    varM = [\"myd_b{}\".format(x) for x in range(1, 8)] \n",
    "    iS = [df.varX.index(var) for var in varS]\n",
    "    iL = [df.varX.index(var) for var in varL]\n",
    "    iM = [df.varX.index(var) for var in varM]\n",
    "    \n",
    "    if opt == 'train':\n",
    "        indSel = np.random.permutation(trainInd)[0:batch]\n",
    "    else:\n",
    "        indSel = testInd\n",
    "    ns = len(indSel)\n",
    "\n",
    "    # Step 1: Create a ns by bX matrix of vals 0 to nMat[indSel, X]\n",
    "    # random.randint(low, high=None, size=None)\n",
    "    rS = np.random.randint(0, nMat[indSel, 0], [bS, ns]).T\n",
    "    rL = np.random.randint(0, nMat[indSel, 1], [bL, ns]).T\n",
    "    rM = np.random.randint(0, nMat[indSel, 2], [bM, ns]).T\n",
    "    \n",
    "    pS = np.stack([pSLst[indSel[k]][rS[k, :]] for k in range(ns)], axis=0)\n",
    "    pL = np.stack([pLLst[indSel[k]][rL[k, :]] for k in range(ns)], axis=0)\n",
    "    pM = np.stack([pMLst[indSel[k]][rM[k, :]] for k in range(ns)], axis=0)\n",
    "    \n",
    "    matS1 = x[:, indSel, :][:, :, iS]\n",
    "    matL1 = x[:, indSel, :][:, :, iL]\n",
    "    matM1 = x[:, indSel, :][:, :, iM]\n",
    "    \n",
    "    xS = np.stack([matS1[pS[k, :], k, :] for k in range(ns)], axis=0)\n",
    "    xL = np.stack([matL1[pL[k, :], k, :] for k in range(ns)], axis=0)\n",
    "    xM = np.stack([matM1[pM[k, :], k, :] for k in range(ns)], axis=0)\n",
    "    \n",
    "    pS = (pS - rho) / rho\n",
    "    pL = (pL - rho) / rho\n",
    "    pM = (pM - rho) / rho\n",
    "    \n",
    "    return (\n",
    "        torch.tensor(xS, dtype=torch.float32),\n",
    "        torch.tensor(xL, dtype=torch.float32),\n",
    "        torch.tensor(xM, dtype=torch.float32),\n",
    "        torch.tensor(pS, dtype=torch.float32),\n",
    "        torch.tensor(pL, dtype=torch.float32),\n",
    "        torch.tensor(pM, dtype=torch.float32),\n",
    "        torch.tensor(xc[indSel, :], dtype=torch.float32),\n",
    "        torch.tensor(yc[indSel, 0], dtype=torch.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "71dec043-744d-45d8-aaa4-dbdde4d0545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSubset(opt='train', batch=1000):\n",
    "    # random sample within window\n",
    "    varS = ['VV', 'VH', 'vh_vv']\n",
    "    varL = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'ndvi', 'ndwi', 'nirv']\n",
    "    varM = [\"myd_b{}\".format(x) for x in range(1, 8)]\n",
    "    iS = [df.varX.index(var) for var in varS]\n",
    "    iL = [df.varX.index(var) for var in varL]\n",
    "    iM = [df.varX.index(var) for var in varM]\n",
    "    \n",
    "    if opt == 'train':\n",
    "        indSel = np.random.permutation(trainInd)[0:batch]\n",
    "    else:\n",
    "        indSel = testInd\n",
    "    ns = len(indSel)\n",
    "\n",
    "    # Step 1: Create a ns by bX matrix of vals 0 to nMat[indSel, X]\n",
    "    # random.randint(low, high=None, size=None)\n",
    "    rS = np.random.randint(0, nMat[indSel, 0], [bS, ns]).T\n",
    "    rL = np.random.randint(0, nMat[indSel, 1], [bL, ns]).T\n",
    "    rM = np.random.randint(0, nMat[indSel, 2], [bM, ns]).T\n",
    "\n",
    "    pDays = []\n",
    "    pS = []\n",
    "    for k in range(ns):\n",
    "        pDays_k = np.zeros(91)\n",
    "        pDays_k[pSLst[indSel[k]]] = 1\n",
    "        pDays.append(pDays_k)\n",
    "        pS_k = pDays_k *np.arange(91)\n",
    "        pS.append(pS_k)\n",
    "    pDays = np.stack(pDays, axis=0)\n",
    "    pS = np.stack(pS, axis=0)\n",
    "    \n",
    "    # pS = np.stack([pSLst[indSel[k]]for k in range(ns)], axis=0)\n",
    "    # pS = np.stack([pSLst[indSel[k]][rS[k, :]] for k in range(ns)], axis=0)\n",
    "    # pL = np.stack([pLLst[indSel[k]][rL[k, :]] for k in range(ns)], axis=0)\n",
    "    # pM = np.stack([pMLst[indSel[k]][rM[k, :]] for k in range(ns)], axis=0)\n",
    "    \n",
    "    matS1 = x[:, indSel, :][:, :, iS]\n",
    "    matL1 = x[:, indSel, :][:, :, iL]\n",
    "    matM1 = x[:, indSel, :][:, :, iM]\n",
    "\n",
    "    xS = np.transpose(matS1, (1, 0, 2))\n",
    "    xS = np.nan_to_num(xS, nan=0)\n",
    "    xL = np.transpose(matL1, (1, 0, 2))\n",
    "    xM = np.transpose(matM1, (1, 0, 2))\n",
    "\n",
    "    # [matS1[~np.isnan(matS1[:, k, 0]), k, :] for k in range(ns)]\n",
    "    # xS = np.stack([matS1[pS[k, :], k, :] for k in range(ns)], axis=0)\n",
    "    # xL = np.stack([matL1[pL[k, :], k, :] for k in range(ns)], axis=0)\n",
    "    # xM = np.stack([matM1[pM[k, :], k, :] for k in range(ns)], axis=0)\n",
    "    \n",
    "    # pS = (pS - rho) / rho\n",
    "    # pL = (pL - rho) / rho\n",
    "    # pM = (pM - rho) / rho\n",
    "    \n",
    "    return (\n",
    "        torch.tensor(xS, dtype=torch.float32),\n",
    "        # torch.tensor(xL, dtype=torch.float32),\n",
    "        # torch.tensor(xM, dtype=torch.float32),\n",
    "        torch.tensor(pS, dtype=torch.float32),\n",
    "        torch.tensor(pDays, dtype=torch.float32)\n",
    "        # torch.tensor(pL, dtype=torch.float32),\n",
    "        # torch.tensor(pM, dtype=torch.float32),\n",
    "        # torch.tensor(xc[indSel, :], dtype=torch.float32),\n",
    "        # torch.tensor(yc[indSel, 0], dtype=torch.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1ddbf1f6-35d4-4548-baa6-ea9f43710e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 91, 3])\n",
      "tensor(False)\n",
      "torch.Size([1000, 91])\n",
      "tensor(False)\n",
      "torch.Size([1000, 91])\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "xS, pS, dS =randomSubset()\n",
    "print(xS.shape)\n",
    "print(torch.sum(torch.isnan(xS)) > 0)\n",
    "print(pS.shape)\n",
    "print(torch.sum(torch.isnan(pS)) > 0)\n",
    "print(dS.shape)\n",
    "print(torch.sum(torch.isnan(dS)) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b0ed0fc5-af77-47c6-aee7-e17b7c0421ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0., 19.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0., 31.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0., 43.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 55.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 67.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 79.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pS[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "29efc2f7-4fc4-4ccc-9ddb-1b72b0884c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dS[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "112f9ebb-7a12-4c0c-932c-d16aaad5a046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.isnan(randomSubset()[0])) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7693cf52-54db-4b27-9cea-9917f3d91f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr =np.zeros(5)\n",
    "arr[p] = 1\n",
    "np.outer(arr[None, ...], arr[None, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "489af0e2-8c3d-4b5b-9d23-be82df81a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "74f71be5-c162-49e2-8d54-4974e4ab2589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 26.7779763677887\n"
     ]
    }
   ],
   "source": [
    "M_avail_days = []\n",
    "for day_arr in pMLst:\n",
    "    M_avail_days.append(len(day_arr))\n",
    "print(max(M_avail_days), np.mean(M_avail_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6377e062-14aa-49d6-bc16-86b5631b4058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 7.627643729520405\n"
     ]
    }
   ],
   "source": [
    "L_avail_days = []\n",
    "for day_arr in pLLst:\n",
    "    L_avail_days.append(len(day_arr))\n",
    "print(max(L_avail_days), np.mean(L_avail_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "571288ef-85d1-4584-8708-704dd7354970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 13.838347731109126\n"
     ]
    }
   ],
   "source": [
    "S_avail_days = []\n",
    "for day_arr in pSLst:\n",
    "    S_avail_days.append(len(day_arr))\n",
    "print(max(S_avail_days), np.mean(S_avail_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1679c0d7-9542-4efa-ba31-f8d9765ee81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 3)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xS = x[:, :, :][:, :, iS]\n",
    "xS[:, 12, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5b72f8ac-54c8-43e6-9838-91142e64675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.outer(arr[None, ...], arr[None, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "98b72d68-cf40-4987-b047-c70492cf8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = np.ones((10, 5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2132c922-d4de-499e-8483-0502ee13c872",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,5,5) (10,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43matt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,5,5) (10,5) "
     ]
    }
   ],
   "source": [
    "att * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc4b17-ce2b-4ed8-a326-cc4f38ae766b",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "effb3d83-e0e1-4009-814e-08cac9b58c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = \"train\"\n",
    "batch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8c9c175-387f-4f99-a8a8-b6ee78af5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt == 'train':\n",
    "    indSel = np.random.permutation(trainInd)[0:batch]\n",
    "else:\n",
    "    indSel = testInd\n",
    "ns = len(indSel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "979c736d-43ed-41f7-8938-d32a471c20c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b2570bab-9ea2-469f-80fd-aa13da3a0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each lfmc in batch, get 8 random vals (w/ rep) from [0, # days for lfmc]\n",
    "rS = np.random.randint(0, nMat[indSel, 0], [bS, ns]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77cb00b9-855c-43da-aec3-15ced5ea3f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nMat[indSel, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "75d76171-e228-4edc-a809-82217d88cf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "064c4eb8-4419-4798-8817-52ab7a1c9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each lfmc in batch, choose 8 days based on vals in rS\n",
    "pS = np.stack([pSLst[indSel[k]][rS[k, :]] for k in range(ns)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f80e5870-9859-4cb1-82c9-a6017d5493a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3da2d211-9bdd-4df3-88b2-17b929f54442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pSLst[ index an lfmc point in the dataset ][ index bS random days ] \n",
    "# pSLst -- for each LFMC data point, a list of days in the 91 day window that have data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "33e52f84-c83d-441a-a01a-ed4bbfde9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "matS1 = x[:, indSel, :][:, :, iS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c2425cde-66ed-412a-a2d3-481b3887faeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 9970, 20)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # (rho, #lfmc, #var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bffce65d-45f4-409f-bb7c-681d6c06db6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 1000, 20)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select examples in batch\n",
    "x[:, indSel, :].shape  # (rho, batch size, #var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5317feb5-f4ed-4905-9ae6-d3a69b7ad120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 1000, 3)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select variables of interest\n",
    "x[:, indSel, :][:, :, iS].shape # (rho, batch size, #var desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e40a2a23-d24a-48a4-9fbd-6dc245fa0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "xS = np.stack([matS1[pS[k, :], k, :] for k in range(ns)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5da73d49-bc89-4789-9d5f-8ecb0273db6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example k, get the 8 days sampled\n",
    "pS[k, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2d5987a0-6dd4-4b22-bc91-30fa572204d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example k, index matS1 for [8 days, example k, all vars of interst]\n",
    "matS1[pS[k, :], k, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8cd1130b-5635-448a-9263-06502d3d6191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xS.shape # (# examples, 8 days, 3 variables of intest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2f4142d4-dd9a-4fc8-8199-a927b411c93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pS = (pS - rho) / rho\n",
    "pS.shape\n",
    "# normalize chose days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1fa1c637-48e0-416b-8a2d-8ce79ccd8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xS -- (1000, bS, 3)\n",
    "# xL -- (1000, bL, 8)\n",
    "# xM -- (1000, bM, 2)\n",
    "\n",
    "# pS -- (1000, bS)\n",
    "# pL -- (1000, bL)\n",
    "# pM -- (1000, bM)\n",
    "\n",
    "# xc -- (1000, 15)\n",
    "# yc -- (1000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad42b6-ff86-487a-b1dd-2128506fa71e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b335598-4d8a-405e-bb37-f40a09496b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeature(nn.Module):\n",
    "    def __init__(self, nTup, nxc, nh):\n",
    "        # nTup -- # of inputs for each satellite\n",
    "        # nxc -- # of const vars\n",
    "        # nh -- # hidden layers\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.lnXc = nn.Sequential(nn.Linear(nxc, nh), nn.ReLU(), nn.Linear(nh, nh))\n",
    "        self.lnLst = nn.ModuleList()\n",
    "        for n in nTup:\n",
    "            self.lnLst.append(\n",
    "                nn.Sequential(nn.Linear(n, nh), nn.ReLU(), nn.Linear(nh, nh))\n",
    "            )\n",
    "\n",
    "    def getPos(self, pos):\n",
    "        nh = self.nh\n",
    "        P = torch.zeros([pos.shape[0], pos.shape[1], nh], dtype=torch.float32)\n",
    "        for i in range(int(nh / 2)):\n",
    "            P[:, :, 2 * i] = torch.sin(pos / (i + 1) * torch.pi)\n",
    "            P[:, :, 2 * i + 1] = torch.cos(pos / (i + 1) * torch.pi)\n",
    "        return P\n",
    "\n",
    "    def forward(self, xTup, pTup, xc):\n",
    "        outLst = list()\n",
    "        for k in range(len(xTup)):\n",
    "            x = self.lnLst[k](xTup[k]) + self.getPos(pTup[k])\n",
    "            outLst.append(x)\n",
    "        outC = self.lnXc(xc)\n",
    "        # outLst[0].shape -> torch.Size([1000, 8, 32])\n",
    "        # outLst[1].shape -> torch.Size([1000, 6, 32])\n",
    "        # outLst[2].shape -> torch.Size([1000, 10, 32])\n",
    "        # outC[:, None, :].shape -> torch.Size([1000, 1, 32])\n",
    "        # out.shape -> torch.Size([1000, 25, 32])\n",
    "        out = torch.cat(outLst + [outC[:, None, :]], dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, nx, nh):\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.W_k = nn.Linear(nx, nh, bias=False)\n",
    "        self.W_q = nn.Linear(nx, nh, bias=False)\n",
    "        self.W_v = nn.Linear(nx, nh, bias=False)\n",
    "        self.W_o = nn.Linear(nh, nh, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = self.W_q(x), self.W_k(x), self.W_v(x)\n",
    "        d = q.shape[1]\n",
    "        score = torch.bmm(q.transpose(1, 2), k) / math.sqrt(d)\n",
    "        attention = torch.softmax(score, dim=-1)\n",
    "        out = torch.bmm(attention, v.transpose(1, 2))\n",
    "        out = self.W_o(out.transpose(1, 2))\n",
    "        return out\n",
    "\n",
    "\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, nh, ny):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(nh, nh)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(nh, ny)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n",
    "\n",
    "\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, norm_shape, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(norm_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "\n",
    "\n",
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, nTup, nxc, nh):\n",
    "        # nTup -- # of inputs for each satellite\n",
    "        # nxc -- # of const vars\n",
    "        # nh -- # hidden layers\n",
    "        super().__init__()\n",
    "        self.nTup = nTup\n",
    "        self.nxc = nxc\n",
    "        self.encoder = InputFeature(nTup, nxc, nh)\n",
    "        self.atten = AttentionLayer(nh, nh)\n",
    "        self.addnorm1 = AddNorm(nh, 0.1)\n",
    "        self.addnorm2 = AddNorm(nh, 0.1)\n",
    "        self.ffn1 = PositionWiseFFN(nh, nh)\n",
    "        self.ffn2 = PositionWiseFFN(nh, 1)\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, x, pos, xcT, lTup):\n",
    "        xIn = self.encoder(x, pos, xcT)\n",
    "        out = self.atten(xIn)\n",
    "        out = self.addnorm1(xIn, out)\n",
    "        out = self.ffn1(out)\n",
    "        out = self.addnorm2(xIn, out)\n",
    "        out = self.ffn2(out)\n",
    "        out = out.squeeze(-1)\n",
    "        k = 0\n",
    "        temp = 0\n",
    "        for i in lTup:\n",
    "            temp = temp + out[:, k : i + k].mean(-1)\n",
    "            k = k + i\n",
    "        temp = temp + out[:, k:].mean(-1)\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5b4f3-78d4-4ae6-b219-7b5fbdfabe04",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d6f3d7d-73f5-4619-aa37-4f9f826ce28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bS = 8\n",
    "bL = 6\n",
    "bM = 10\n",
    "nh = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8bdc2999-a92e-44d1-8510-1c4d33d71838",
   "metadata": {},
   "outputs": [],
   "source": [
    "xS, xL, xM, pS, pL, pM, xcT, yT = randomSubset()\n",
    "nTup = (xS.shape[-1], xL.shape[-1], xM.shape[-1])\n",
    "lTup = (xS.shape[1], xL.shape[1], xM.shape[1])\n",
    "nxc = xc.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "346d2aa9-7a23-4a46-902b-7c4d8ec8d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinalModel(nTup, nxc, nh)\n",
    "yP = model((xS, xL, xM), (pS, pL, pM), xcT, lTup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3dcd75ed-424a-4b8f-b749-d6e857ef6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss(reduction='mean')\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.LinearLR(\n",
    "    optimizer, start_factor=1.0, end_factor=0.01, total_iters=800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab50d5-a9db-4937-94c3-3d8e2418fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "nEp = 500\n",
    "nIterEp = 20\n",
    "for ep in range(nEp):\n",
    "    lossEp = 0\n",
    "    for i in range(nIterEp):\n",
    "        t0 = time.time()\n",
    "        xS, xL, xM, pS, pL, pM, xcT, yT = randomSubset()\n",
    "        t1 = time.time()\n",
    "        model.zero_grad()\n",
    "        yP = model((xS, xL, xM), (pS, pL, pM), xcT, lTup)\n",
    "        loss = loss_fn(yP, yT)\n",
    "        loss.backward()\n",
    "        t2 = time.time()\n",
    "        lossEp = lossEp + loss.item()\n",
    "        optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    xS, xL, xM, pS, pL, pM, xcT, yT = randomSubset('test')\n",
    "    yP = model((xS, xL, xM), (pS, pL, pM), xcT, lTup)\n",
    "    loss = loss_fn(yP, yT)\n",
    "    corr = np.corrcoef(yP.detach().numpy(), yT.detach().numpy())[0, 1]\n",
    "    if ep > 200:\n",
    "        scheduler.step()\n",
    "    print(\n",
    "        '{} {:.3f} {:.3f} {:.3f} time {:.2f} {:.2f}'.format(\n",
    "            ep, lossEp / nIterEp, loss.item(), corr, t1 - t0, t2 - t1\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
