{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# hydroDL module by Kuai Fang\n",
    "from hydroDL.data import dbVeg\n",
    "from hydroDL.data import DataModel\n",
    "from hydroDL.master import dataTs2Range\n",
    "from hydroDL import kPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 45 # init rho\n",
    "dataName = 'singleDaily-modisgrid-new-const' # init dataName\n",
    "# importlib.reload(hydroDL.data.dbVeg) # reimport library\n",
    "df = dbVeg.DataFrameVeg(dataName) # create DataFrameVeg class \n",
    "dm = DataModel(X=df.x, XC=df.xc, Y=df.y) # (?) create DataModel class (contains many confusing functions) \n",
    "siteIdLst = df.siteIdLst # get site list\n",
    "dm.trans(mtdDefault='minmax') # (?) some sort of data normalization\n",
    "dataTup = dm.getData() # get x, xc, y, and yc\n",
    "dataEnd, (iInd, jInd) = dataTs2Range(dataTup, rho, returnInd=True) # get data into form (# LFMC, 91 day window, varX) \n",
    "x, xc, y, yc = dataEnd # data from dataTs2Range\n",
    "iInd = np.array(iInd)\n",
    "jInd = np.array(jInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quality\n",
    "thresh = 0.4\n",
    "\n",
    "# get land cover percentages for quality sites\n",
    "lc_idx = [df.varXC.index(var) for var in df.varXC[-6:]]\n",
    "lc_pct = df.xc[:, lc_idx]\n",
    "top_lc = np.argmax(lc_pct, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_version = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_path = os.path.join(kPath.dirVeg, 'model', 'attention', split_version, 'subset.json')\n",
    "with open(splits_path) as f:\n",
    "    splits_dict = json.load(f)\n",
    "\n",
    "data = {\n",
    "    'fold' : range(5),\n",
    "    '# train examples' : [len(splits_dict[f'trainInd_k{fold}5']) for fold in range(5)],\n",
    "    '# test examples' : [len(splits_dict[f'testInd_k{fold}5']) for fold in range(5)],\n",
    "    '# train sites' : [len(splits_dict[f'trainSite_k{fold}5']) for fold in range(5)],\n",
    "    '# test sites' : [len(splits_dict[f'testSite_k{fold}5']) for fold in range(5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     data[f'# train sites lc={i}'] = [0] * 5\n",
    "#     data[f'# test sites lc={i}'] = [0] * 5\n",
    "#     # data[f'# train examples lc={i}'] = [0] * 5\n",
    "#     # data[f'# test examples lc={i}'] = [0] * 5\n",
    "\n",
    "# for fold in range(5):\n",
    "#     for land_cover_id in range(6):\n",
    "#         for site in splits_dict[f'trainSite_k{fold}5']: \n",
    "#             if top_lc[site] != land_cover_id:\n",
    "#                 continue\n",
    "#             data[f'# train sites lc={top_lc[site]}'][fold] += 1\n",
    "#             # data[f'# train examples lc={top_lc[site]}'][fold] += len(np.where(np.isin(jInd, site))[0])\n",
    "#         for site in splits_dict[f'testSite_k{fold}5']: \n",
    "#             if top_lc[site] != land_cover_id:\n",
    "#                 continue\n",
    "#             data[f'# test sites lc={top_lc[site]}'][fold] += 1\n",
    "#             # data[f'# test examples lc={top_lc[site]}'][fold] += len(np.where(np.isin(jInd, site))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    data[f'# train sites lc={i}'] = [0] * 5\n",
    "    data[f'# test sites lc={i}'] = [0] * 5\n",
    "    # data[f'# train examples lc={i}'] = [0] * 5\n",
    "    # data[f'# test examples lc={i}'] = [0] * 5\n",
    "\n",
    "for fold in range(5):\n",
    "    for land_cover_id in range(6):\n",
    "        data[f'# train sites lc={land_cover_id}'][fold] = np.sum(top_lc[splits_dict[f'trainSite_k{fold}5']] == land_cover_id)\n",
    "        data[f'# test sites lc={land_cover_id}'][fold] = np.sum(top_lc[splits_dict[f'testSite_k{fold}5']] == land_cover_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    # data[f'# train sites lc={i} 2'] = [0] * 5\n",
    "    # data[f'# test sites lc={i} 2'] = [0] * 5\n",
    "    data[f'# train examples lc={i}'] = [0] * 5\n",
    "    data[f'# test examples lc={i}'] = [0] * 5\n",
    "\n",
    "for site in range(335):\n",
    "    for fold in range(5):\n",
    "        lc = top_lc[site]\n",
    "        if site in splits_dict[f'trainSite_k{fold}5']:\n",
    "            data[f'# train examples lc={lc}'][fold] += len(np.where(np.isin(jInd, site))[0])\n",
    "        if site in splits_dict[f'testSite_k{fold}5']:\n",
    "            data[f'# test examples lc={lc}'][fold] += len(np.where(np.isin(jInd, site))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_csv(f'{kPath.dirVeg}random_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_csv(f'{kPath.dirVeg}stratified_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold': range(0, 5),\n",
       " '# train examples': [6282, 6257, 6249, 6341, 6323],\n",
       " '# test examples': [1581, 1606, 1614, 1522, 1540],\n",
       " '# train sites': [126, 126, 126, 127, 127],\n",
       " '# test sites': [32, 32, 32, 31, 31],\n",
       " '# train sites lc=0': [3, 3, 3, 2, 1],\n",
       " '# test sites lc=0': [0, 0, 0, 1, 2],\n",
       " '# train sites lc=1': [36, 34, 39, 42, 41],\n",
       " '# test sites lc=1': [12, 14, 9, 6, 7],\n",
       " '# train sites lc=2': [3, 4, 4, 2, 3],\n",
       " '# test sites lc=2': [1, 0, 0, 2, 1],\n",
       " '# train sites lc=3': [60, 63, 63, 58, 60],\n",
       " '# test sites lc=3': [16, 13, 13, 18, 16],\n",
       " '# train sites lc=4': [20, 19, 14, 18, 17],\n",
       " '# test sites lc=4': [2, 3, 8, 4, 5],\n",
       " '# train sites lc=5': [4, 3, 3, 5, 5],\n",
       " '# test sites lc=5': [1, 2, 2, 0, 0],\n",
       " '# train examples lc=0': [110, 110, 110, 73, 37],\n",
       " '# test examples lc=0': [0, 0, 0, 37, 73],\n",
       " '# train examples lc=1': [1668, 1544, 1855, 1953, 1932],\n",
       " '# test examples lc=1': [570, 694, 383, 285, 306],\n",
       " '# train examples lc=2': [123, 165, 165, 82, 125],\n",
       " '# test examples lc=2': [42, 0, 0, 83, 40],\n",
       " '# train examples lc=3': [3169, 3376, 3273, 3074, 3148],\n",
       " '# test examples lc=3': [841, 634, 737, 936, 862],\n",
       " '# train examples lc=4': [1072, 1020, 753, 967, 916],\n",
       " '# test examples lc=4': [110, 162, 429, 215, 266],\n",
       " '# train examples lc=5': [215, 107, 168, 245, 245],\n",
       " '# test examples lc=5': [30, 138, 77, 0, 0]}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
