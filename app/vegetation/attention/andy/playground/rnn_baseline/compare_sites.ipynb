{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare sites\n",
    "\n",
    "**Purpose:** We want to compare metrics by the RNN maps to predictions by the transformer model. We will compare performance on the sites that neither model was trained on. This script determines those sites.\n",
    "\n",
    "**Date:** Aug 1, 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydroDL import kPath\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sites: 150\n"
     ]
    }
   ],
   "source": [
    "# RNN train sites\n",
    "rnn_df_path = '/Users/andyhuynh/Documents/lfmc/data/predictions/lstm_input_data_pure+all_same_28_may_2019_res_SM_gap_3M'\n",
    "rnn_df = pd.read_pickle(rnn_df_path)\n",
    "rnn_train_sites = rnn_df['site'].unique().tolist()\n",
    "\n",
    "print(\"number of sites:\", len(rnn_train_sites))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sites: 177\n",
      "number of quality sites: 32\n",
      "number of poor sites: 145\n"
     ]
    }
   ],
   "source": [
    "# Transformer train/test sites\n",
    "transformer_df_path = '/Users/andyhuynh/Documents/lfmc/data/model/data/singleDaily-nadgrid/site.csv'\n",
    "transformer_df = pd.read_csv(transformer_df_path)\n",
    "\n",
    "# Get splits\n",
    "splits_path = os.path.join(kPath.dirVeg, 'model', 'attention', 'dataset')\n",
    "splits_json = os.path.join(splits_path, 'subset.json')\n",
    "\n",
    "with open(splits_json) as json_file:\n",
    "    splits = json.load(json_file)\n",
    "\n",
    "quality_test_sites = splits['testSite_k05']\n",
    "poor_test_sites = splits['testSite_underThresh']\n",
    "test_sites = quality_test_sites + poor_test_sites\n",
    "\n",
    "print(\"number of sites:\", len(test_sites))\n",
    "print(\"number of quality sites:\", len(quality_test_sites))\n",
    "print(\"number of poor sites:\", len(poor_test_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sites:  161\n"
     ]
    }
   ],
   "source": [
    "# all test sites\n",
    "transformer_test_df = transformer_df.iloc[test_sites]\n",
    "transformer_test_sites = transformer_test_df['siteName'].unique().tolist()\n",
    "\n",
    "non_train_siteNames_both_models = set(transformer_test_sites) - set(rnn_train_sites)\n",
    "non_train_siteIds_both_models = transformer_test_df[transformer_test_df.siteName.isin(non_train_siteNames_both_models)].siteId\n",
    "\n",
    "out_path = os.path.join(kPath.dirVeg, 'predictions/non_train_siteIds_both_models_all.csv')\n",
    "non_train_siteIds_both_models.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"number of sites:\", len(non_train_siteIds_both_models))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sites: 20\n"
     ]
    }
   ],
   "source": [
    "# quality test sites\n",
    "transformer_test_df = transformer_df.iloc[quality_test_sites]\n",
    "transformer_test_sites = transformer_test_df['siteName'].unique().tolist()\n",
    "\n",
    "non_train_siteNames_both_models = set(transformer_test_sites) - set(rnn_train_sites)\n",
    "non_train_siteIds_both_models = transformer_test_df[transformer_test_df.siteName.isin(non_train_siteNames_both_models)].siteId\n",
    "\n",
    "out_path = os.path.join(kPath.dirVeg, 'predictions/non_train_siteIds_both_models_quality.csv')\n",
    "non_train_siteIds_both_models.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"number of sites:\", len(non_train_siteIds_both_models))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sites: 141\n"
     ]
    }
   ],
   "source": [
    "# poor test sites\n",
    "transformer_test_df = transformer_df.iloc[poor_test_sites]\n",
    "transformer_test_sites = transformer_test_df['siteName'].unique().tolist()\n",
    "\n",
    "non_train_siteNames_both_models = set(transformer_test_sites) - set(rnn_train_sites)\n",
    "non_train_siteIds_both_models = transformer_test_df[transformer_test_df.siteName.isin(non_train_siteNames_both_models)].siteId\n",
    "\n",
    "out_path = os.path.join(kPath.dirVeg, 'predictions/non_train_siteIds_both_models_poor.csv')\n",
    "non_train_siteIds_both_models.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"number of sites:\", len(non_train_siteIds_both_models))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
