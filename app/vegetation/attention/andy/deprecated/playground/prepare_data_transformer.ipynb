{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for transformers\n",
    "\n",
    "**Purpose:** We want to compare metrics by the RNN maps to predictions by the transformer model. Our transformer mdoel currenlty takes in inputs of size `(rho, num observations, num inputs)`. To get the daily prediction at each site, we have to prepare this matrix.\n",
    "\n",
    "**Date:** July 30, 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows the `models/cherry_pick/data.py` and `models/all_pick/data.py` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading package hydroDL\n"
     ]
    }
   ],
   "source": [
    "# hydroDL module by Kuai Fang\n",
    "import hydroDL.data.dbVeg\n",
    "from hydroDL.data import dbVeg\n",
    "from hydroDL.data import DataModel\n",
    "from hydroDL.master import dataTs2Range\n",
    "from hydroDL import kPath\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = \"singleDaily-nadgrid\"\n",
    "rho = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with custom DataFrameVeg and DataModel classes\n",
    "df = dbVeg.DataFrameVeg(dataName)\n",
    "dm = DataModel(X=df.x, XC=df.xc, Y=df.y)\n",
    "dm.trans(mtdDefault='minmax') # Min-max normalization\n",
    "dataTup = dm.getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we fill the `y` matrix with all ones. This is quick temporary and hacky way to quickly format the data for the transformer. \n",
    "\n",
    "The `dataTs2Range` method in the following line prepares the data by reformatting it to shape `(rho, num observations, num inputs)`. In our case, we do not want to limit just to `num observations`. Rathe, we want to keep ALL the remote sensing data in order to retrieve daily LFMC prediction from the study period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, xc, y, _ = dataTup\n",
    "dataTup = (x, xc, np.ones(y.shape), _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert data to shape (Number of observations, rho, number of input features)\n",
    "dataEnd, (iInd, jInd) = dataTs2Range(dataTup, rho, returnInd=True) # iInd: day, jInd: site\n",
    "x, xc, _, yc = dataEnd \n",
    "\n",
    "iInd = np.array(iInd) # TODO: Temporary fix\n",
    "jInd = np.array(jInd) # TODO: emporary fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# satellite variable names\n",
    "varS = ['VV', 'VH', 'vh_vv']\n",
    "varL = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'ndvi', 'ndwi', 'nirv']\n",
    "varM = [\"MCD43A4_b{}\".format(x) for x in range(1, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "iInd = np.array(iInd) # TODO: Temporary fix\n",
    "jInd = np.array(jInd) # TODO: emporary fix\n",
    "\n",
    "iS = [df.varX.index(var) for var in varS]\n",
    "iL = [df.varX.index(var) for var in varL]\n",
    "iM = [df.varX.index(var) for var in varM]\n",
    "\n",
    "# For each remote sensing source (i.e. Sentinel, MODIS), for each LFMC observaton,\n",
    "# create a list of days in the rho-window that have data \n",
    "# nMat: Number of days each satellite has data for, of shape (# obsevations, # satellites)\n",
    "pSLst, pLLst, pMLst = list(), list(), list()\n",
    "nMat = np.zeros([yc.shape[0], 3])\n",
    "for k in range(nMat.shape[0]):\n",
    "    tempS = x[:, k, iS]\n",
    "    pS = np.where(~np.isnan(tempS).any(axis=1))[0]\n",
    "    tempL = x[:, k, iL]\n",
    "    pL = np.where(~np.isnan(tempL).any(axis=1))[0]\n",
    "    tempM = x[:, k, iM]\n",
    "    pM = np.where(~np.isnan(tempM).any(axis=1))[0]\n",
    "    pSLst.append(pS)\n",
    "    pLLst.append(pL)\n",
    "    pMLst.append(pM)\n",
    "    nMat[k, :] = [len(pS), len(pL), len(pM)]\n",
    "\n",
    "# only keep if data if there is at least 1 day of data for each remote sensing source\n",
    "indKeep = np.where((nMat > 0).all(axis=1))[0]\n",
    "x = x[:, indKeep, :]\n",
    "xc = xc[indKeep, :]\n",
    "yc = yc[indKeep, :]\n",
    "nMat = nMat[indKeep, :]\n",
    "pSLst = [pSLst[k] for k in indKeep]\n",
    "pLLst = [pLLst[k] for k in indKeep]\n",
    "pMLst = [pMLst[k] for k in indKeep]\n",
    "\n",
    "jInd = jInd[indKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(10)\n",
    "b = np.zeros(10)\n",
    "np.concatenate([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10).shape()\n",
    "b = np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04216492, 0.38305902],\n",
       "       [0.66129926, 0.12741888],\n",
       "       [0.6074255 , 0.56743243],\n",
       "       [0.01837205, 0.88331768],\n",
       "       [0.21977481, 0.37993062],\n",
       "       [0.32463266, 0.95190576],\n",
       "       [0.05082871, 0.43167692],\n",
       "       [0.72797715, 0.49819248],\n",
       "       [0.65345978, 0.59968182],\n",
       "       [0.69760439, 0.08436677]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfmc_daily = np.load(os.path.join(kPath.dirVeg, \"transformer_lfmc_daily.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = 45\n",
    "len(lfmc_daily[lfmc_daily[:, 2] == site])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 45.,  46.,  54.,  58.,  61.,  66.,  68.,  72.,  74.,  76.,  81.,\n",
       "        82.,  83.,  86.,  90.,  91.,  92.,  93.,  95.,  96.,  97.,  98.,\n",
       "       104., 106., 109., 112., 117., 118., 119., 120., 121., 122., 123.,\n",
       "       124., 125., 127., 129., 131., 133., 135., 138., 140., 142., 144.,\n",
       "       145., 146., 147., 148., 149., 151., 152., 154., 157., 158., 159.,\n",
       "       161., 162., 163., 164., 165., 166., 167., 176., 177., 178., 179.,\n",
       "       180., 181., 182., 185., 186., 187., 188., 189., 191., 192., 193.,\n",
       "       194., 198., 199., 200., 201., 202., 203., 204., 205., 206., 207.,\n",
       "       208., 209., 210., 211., 213., 215., 217., 223., 225., 228., 236.,\n",
       "       237., 243., 244., 245., 246., 251., 252., 253., 254., 255., 256.,\n",
       "       257., 269., 270., 271., 272., 274., 275., 276., 280., 282., 286.,\n",
       "       287., 289., 290., 291., 292., 293., 294., 295., 296., 297., 298.,\n",
       "       299., 300., 305., 307., 308., 309., 310., 311., 312., 313., 314.,\n",
       "       315., 316., 317., 318., 319., 320., 322., 324., 325., 327.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lfmc_daily[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "        22.,  23.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,\n",
       "        34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,\n",
       "        45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,\n",
       "        56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,  66.,\n",
       "        67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,  77.,\n",
       "        78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,\n",
       "        89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99.,\n",
       "       100., 101., 102., 103., 104., 105., 106., 107., 108., 109., 110.,\n",
       "       111., 112., 113., 114., 115., 116., 117., 118., 119., 120., 121.,\n",
       "       122., 123., 124., 125., 126., 127., 128., 129., 130., 131., 132.,\n",
       "       133., 134., 135., 136., 137., 138., 139., 140., 141., 142., 143.,\n",
       "       144., 145., 146., 147., 148., 149., 150., 151., 152., 153., 154.,\n",
       "       155., 156., 157., 158., 159., 160., 161., 162., 163., 164., 165.,\n",
       "       166., 167., 168., 169., 170., 171., 172., 173., 174., 175., 176.,\n",
       "       177., 178., 179., 180., 181., 182., 183., 184., 185., 186., 187.,\n",
       "       188., 189., 190., 191., 192., 193., 194., 195., 196., 197., 198.,\n",
       "       199., 200., 201., 202., 203., 204., 205., 206., 207., 208., 209.,\n",
       "       210., 211., 212., 213., 214., 215., 216., 217., 218., 219., 220.,\n",
       "       221., 222., 223., 224., 225., 226., 227., 228., 229., 230., 231.,\n",
       "       232., 233., 234., 235., 236., 237., 238., 239., 240., 241., 242.,\n",
       "       243., 244., 245., 246., 247., 248., 249., 250., 251., 252., 253.,\n",
       "       254., 255., 256., 257., 258., 259., 260., 261., 262., 263., 264.,\n",
       "       265., 266., 267., 268., 269., 270., 271., 272., 273., 274., 275.,\n",
       "       276., 277., 278., 279., 280., 281., 282., 283., 284., 285., 286.,\n",
       "       287., 288., 289., 290., 291., 292., 293., 294., 295., 296., 297.,\n",
       "       298., 299., 300., 301., 302., 303., 304., 305., 306., 307., 308.,\n",
       "       309., 310., 311., 312., 313., 314., 315., 316., 317., 318., 319.,\n",
       "       320., 321., 322., 323., 324., 325., 326., 327., 328., 329., 330.,\n",
       "       331., 332., 333., 334.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lfmc_daily[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
