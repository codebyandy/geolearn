{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from hydroDL.model import trainBasin, crit, waterNetTest\n",
    "from hydroDL.data import dbBasin, gageII\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from hydroDL.model import waterNetTest\n",
    "import importlib\n",
    "from hydroDL.utils import torchUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataName = 'QN90ref'\n",
    "# dataName = 'temp'\n",
    "DF = dbBasin.DataFrameBasin(dataName)\n",
    "varX = ['pr', 'etr', 'tmmn', 'tmmx', 'srad', 'LAI']\n",
    "mtdX = ['skip' for k in range(2)] +\\\n",
    "    ['scale' for k in range(2)] +\\\n",
    "    ['norm' for k in range(2)]\n",
    "varY = ['runoff']\n",
    "mtdY = ['skip']\n",
    "varXC = gageII.varLstEx\n",
    "# mtdXC = dbBasin.io.extractVarMtd(varXC)\n",
    "# mtdXC = ['QT' for var in varXC]\n",
    "mtdXC = ['QT' for var in varXC]\n",
    "varYC = None\n",
    "mtdYC = dbBasin.io.extractVarMtd(varYC)\n",
    "\n",
    "# train\n",
    "trainSet = 'WYB09'\n",
    "testSet = 'WYA09'\n",
    "DM1 = dbBasin.DataModelBasin(\n",
    "    DF, subset=trainSet, varX=varX, varXC=varXC, varY=varY, varYC=varYC)\n",
    "DM1.trans(mtdX=mtdX, mtdXC=mtdXC)\n",
    "dataTup1 = DM1.getData()\n",
    "DM2 = dbBasin.DataModelBasin(\n",
    "    DF, subset=testSet, varX=varX, varXC=varXC, varY=varY, varYC=varYC)\n",
    "DM2.borrowStat(DM1)\n",
    "dataTup2 = DM2.getData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model\n",
    "nh = 16\n",
    "ng = len(varXC)\n",
    "ns = len(DF.siteNoLst)\n",
    "nr = 5\n",
    "model = waterNetTest.WaterNet0119(nh, len(varXC), nr)\n",
    "model = model.cuda()\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "lossFun = crit.LogLoss2D().cuda()\n",
    "sn = 1e-8\n",
    "ns = len(DF.siteNoLst)\n",
    "sizeLst = trainBasin.getSize(dataTup1)\n",
    "[x, xc, y, yc] = dataTup1\n",
    "[nx, nxc, ny, nyc, nt, ns] = sizeLst\n",
    "model.train()\n",
    "batchSize = [1000, 100]\n",
    "[rho, nbatch] = batchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nIterEp = int(np.ceil(np.log(0.01)/np.log(1 - nbatch*rho/2000/nt)))\n",
    "nIterEp = int(np.ceil((ns*nt)/(nbatch*rho)))\n",
    "lossLst = list()\n",
    "saveDir = r'/scratch/users/kuaifang/temp/'\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "for ep in range(1, 1001):\n",
    "    for iter in range(nIterEp):\n",
    "        [rho, nbatch] = batchSize\n",
    "        iS = np.random.randint(0, ns, [nbatch])\n",
    "        iT = np.random.randint(0, nt-rho, [nbatch])\n",
    "        xTemp = np.full([rho, nbatch, nx], np.nan)\n",
    "        xcTemp = np.full([nbatch, nxc], np.nan)\n",
    "        yTemp = np.full([rho, nbatch, ny], np.nan)\n",
    "        ycTemp = np.full([nbatch, nyc], np.nan)\n",
    "        if x is not None:\n",
    "            for k in range(nbatch):\n",
    "                xTemp[:, k, :] = x[iT[k]+1:iT[k]+rho+1, iS[k], :]\n",
    "        if y is not None:\n",
    "            for k in range(nbatch):\n",
    "                yTemp[:, k, :] = y[iT[k]+1:iT[k]+rho+1, iS[k], :]\n",
    "        if xc is not None:\n",
    "            xcTemp = xc[iS, :]\n",
    "        if yc is not None:\n",
    "            ycTemp = yc[iS, :]\n",
    "        xT = torch.from_numpy(xTemp).float().cuda()\n",
    "        xcT = torch.from_numpy(xcTemp).float().cuda()\n",
    "        yT = torch.from_numpy(yTemp).float().cuda()\n",
    "        ycT = torch.from_numpy(ycTemp).float().cuda()\n",
    "        model.zero_grad()\n",
    "        yP = model(xT, xcT)\n",
    "        loss = lossFun(yP[:, :, None], yT[nr-1:, :, :])\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # torchUtils.ifNan(model)\n",
    "        print(ep, iter, loss.item())\n",
    "        lossLst.append(loss.item())\n",
    "    if ep % 50 == 0:\n",
    "        modelFile = os.path.join(\n",
    "            saveDir, 'wn0119-{}-ep{}'.format(dataName, ep))\n",
    "        torch.save(model.state_dict(), modelFile)\n",
    "\n",
    "lossFile = os.path.join(saveDir, 'loss-{}'.format('wn0119'))\n",
    "pd.DataFrame(lossLst).to_csv(lossFile, index=False, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
